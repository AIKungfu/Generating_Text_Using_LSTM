{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text using LSTM\n",
    "**Result:**\n",
    "- **seed**: was just in time to hear it s\n",
    "\n",
    "- **output**: olethmy **and** bs iave aspu wale tuch lnlely **and see as** oncered werpenceradle **of** lt a *vhry* clarfe of toame **of the** werling **but the** waid **to the** wenl **of the** senembobtooo **as** *homd* **the** afded **a said on her** fach **on** *wher stpp* anice **as** speshngs **the** moew **the** waid **to alice said** bester whe hrownan **and** oore tatsed **by** tuatted poly **as** umeer **the said** tomeiers rres tuleking **to the** tueenened **of** toeased herser tenarked **out** *repembir* ins tie *finis* int ttill ie sayher **when** tuch a pear *hirself* anice **as** snee to deer or sle\n",
    "\n",
    "**Approach:**\n",
    "- Added **'#'** character as padding with index value=0\n",
    "- Used 2 LSTMs with **Masking Layer** to skip '#'(padding) while training\n",
    "- Used **Dropout everywhere** for input & output vector units\n",
    "- **No Dropout** before Dense layer \n",
    "\n",
    "**Loss: 0.7253**\n",
    "\n",
    "**Total Epochs: 100, Batch Size:384**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "KCfSsYh7OzmD",
    "outputId": "3c4a3851-c94e-461c-d5a3-0a0aafd9de40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Masking\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ljMPc6_O4vm"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"mystory.txt\"\n",
    "raw_text = open(filename,encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "MZR46A86PAik",
    "outputId": "463e5dc2-7946-4cef-951a-1de9d32dc313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Lines: 3328\n"
     ]
    }
   ],
   "source": [
    "# Total number of line in text\n",
    "total_lines = 0\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f:\n",
    "        total_lines += 1\n",
    "print(\"Total Lines:\",total_lines )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErtvNEh1gJXU"
   },
   "source": [
    "#### Data Preprocessing\n",
    "- Remove Punctuation from string\n",
    "- Remove Blank line from string\n",
    "- char to int & int to char array for a-z & ' '\n",
    "- Create Input (dataX) & output label (dataY)\n",
    "- Add padding if input string length less than 72 (Maxlength of string)\n",
    "- Reshape Input to [samples, time steps, features]\n",
    "- Normalize Input X & One hot vector representation of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJtm_dADdruy"
   },
   "outputs": [],
   "source": [
    "# Punctuation Removal funcation \n",
    "def Punctuation_Removal(str_value): \n",
    "  \n",
    "    punctuation_list = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "  \n",
    "    for x in str_value.lower(): \n",
    "        if x in punctuation_list: \n",
    "            str_value = str_value.replace(x, \"\") \n",
    "  \n",
    "    return str_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7FbHZh6JDNkZ",
    "outputId": "73644fa3-d241-496d-abad-6b4e629c4e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total line with blanks: 4317\n",
      "Final Total Line: 2845\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~ Remove Punctuation from string ~~~~~~~~~~\n",
    "mytext = Punctuation_Removal(raw_text)\n",
    "mytext = mytext.replace('\\n','.')\n",
    "mytext = mytext.replace('\\ufeff','')\n",
    "mytext = mytext.split('.')\n",
    "print(\"Total line with blanks: \"+str(len(mytext)))\n",
    "\n",
    "# ~~~~~~~~~~ Remove Blank line from text ~~~~~~~~~~~\n",
    "final_text = []\n",
    "for line in mytext:\n",
    "  if line == '':\n",
    "    continue\n",
    "  final_text.append(line)\n",
    "print(\"Final Total Line: \"+str(len(final_text)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "L_Fb46G7K8Dm",
    "outputId": "33f69339-34ae-438e-cda6-a359dcabd789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Character list: \n",
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Find unique value into text:  'A-Z' +  ' '\n",
    "\n",
    "mystr = ' '.join(final_text) #join all sentences\n",
    "chars = sorted(list(set(mystr))) #Find unique value & sorting them\n",
    "print(\"Unique Character list: \"+ '\\n'+ str(chars) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7h06RqbKLOJ9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding '#' as padding character \n",
      "\n",
      "Char_to_int array: \n",
      "{' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27, '#': 0}\n",
      "\n",
      "int_to_char array: \n",
      "{1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z', 0: '#'}\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~ char_to_int ~~~~~~~~~~\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars,1)) #start enum with 1 value\n",
    "\n",
    "# ~~~ Used '#' as a padding letter ~~\n",
    "char_to_int['#'] = 0\n",
    "print(\"Adding \\'#\\' as padding character \\n\")\n",
    "print(\"Char_to_int array: \"+'\\n'+ str(char_to_int) + '\\n')\n",
    "\n",
    "\n",
    "# ~~~~~~~~ int_to_char ~~~~~~~~~\n",
    "int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "print(\"int_to_char array: \"+ '\\n' + str(int_to_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAed1C0k7xaC"
   },
   "outputs": [],
   "source": [
    "# Create Input dataX & output label dataY\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for line in final_text:\n",
    "  for i in range(1,len(line)):\n",
    "    seq_in = line[:i]\n",
    "    seq_out = line[i]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "2AlClCn_Umol",
    "outputId": "4f99f01d-4eb9-4304-b4f5-2080e3b0581d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 4 lines of story:\n",
      "\n",
      "chapter i\n",
      " down the rabbithole\n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank and of having nothing to do once or twice she had peeped into the\n"
     ]
    }
   ],
   "source": [
    "num = 4\n",
    "print(\"First {} lines of story:\".format(num)+'\\n')\n",
    "for i in range(num):\n",
    "  print(final_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "U4JGZLDKUSIk",
    "outputId": "283177a3-88ea-4979-803a-3f92f360b71a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input & Output Pair\n",
      "\n",
      "input:  d     output: o\n",
      "input:  do     output: w\n",
      "input:  dow     output: n\n",
      "input:  down     output:  \n",
      "input:  down      output: t\n",
      "input:  down t     output: h\n",
      "input:  down th     output: e\n",
      "input:  down the     output:  \n",
      "input:  down the      output: r\n",
      "input:  down the r     output: a\n",
      "input:  down the ra     output: b\n",
      "input:  down the rab     output: b\n",
      "input:  down the rabb     output: i\n",
      "input:  down the rabbi     output: t\n",
      "input:  down the rabbit     output: h\n",
      "input:  down the rabbith     output: o\n",
      "input:  down the rabbitho     output: l\n",
      "input:  down the rabbithol     output: e\n",
      "input: a     output: l\n",
      "input: al     output: i\n",
      "input: ali     output: c\n",
      "input: alic     output: e\n",
      "input: alice     output:  \n",
      "input: alice      output: w\n",
      "input: alice w     output: a\n",
      "input: alice wa     output: s\n"
     ]
    }
   ],
   "source": [
    "print(\"Input & Output Pair\\n\")\n",
    "for i in range(9,35):\n",
    "  print(\"input:\", ''.join([int_to_char[j]  for j in list(dataX[i])]) ,\n",
    "    \"    output:\",''.join(int_to_char[dataY[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "hpaX74roXw97",
    "outputId": "d77c4789-d790-4328-eb8d-6b8ceb7dedcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max lenght of line: 72\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~ Find Max line length in text ~~~~~~~~\n",
    "maxlen=0\n",
    "for line in dataX:\n",
    "  if maxlen<len(line):\n",
    "    maxlen=len(line)\n",
    "print(\"Max lenght of line: \"+str(maxlen))\n",
    "\n",
    "# ~~~~~~~~ Add Padding for line < maxlen(=72 in our case) ~~~~~~~\n",
    "dataX_padded = pad_sequences(dataX, maxlen=maxlen, padding='post',value=0,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "EgrE0ZZnYFyC",
    "outputId": "f62f10c9-fb60-4a23-8457-ce347d2a7ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns/Input in our dataset:  129829\n",
      "Total vocab ['a-z' and ' '] excluding padding '#' : 27\n",
      "\n",
      "dataX_padded:\n",
      "[[ 4  0  0 ...  0  0  0]\n",
      " [ 4  9  0 ...  0  0  0]\n",
      " [ 4  9  2 ...  0  0  0]\n",
      " ...\n",
      " [19  6 14 ...  0  0  0]\n",
      " [19  6 14 ...  0  0  0]\n",
      " [19  6 14 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX_padded)\n",
    "print(\"Total Patterns/Input in our dataset: \", n_patterns)\n",
    "\n",
    "n_vocab = len(chars) # chars = list of unique values\n",
    "print(\"Total vocab ['a-z' and ' '] excluding padding \\'#\\' :\" , n_vocab)\n",
    "\n",
    "print(\"\\ndataX_padded:\\n\"+str(dataX_padded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrEAajtKYIzb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:           (sample,steps,features)\n",
      "Shape of input X:  (129829, 72, 1)\n",
      "Shape of output Y:  (129829, 28)\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "features=1\n",
    "X = np.reshape(dataX_padded, (n_patterns, maxlen, features))\n",
    "\n",
    "# normalize input X\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "Y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(\"Shape:           (sample,steps,features)\")\n",
    "print(\"Shape of input X: \", str(X.shape))\n",
    "print(\"Shape of output Y: \",str(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNoBmugJcxJF"
   },
   "source": [
    "### Train Model\n",
    "\n",
    "- `Masking Layer`: Skip padding char using masking value=0 while training\n",
    "\n",
    "- Use `2 LSTMs with dropout everywhere` (Input vector & output vector units) \n",
    "\n",
    "- `No Dropout` before Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llTnSfaBgew9"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Masking(mask_value=0, input_shape=(maxlen, features)))\n",
    "\n",
    "model.add(LSTM(256,  dropout=0.1, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(256,  dropout=0.1))\n",
    "\n",
    "model.add(Dense(Y.shape[1], activation='softmax')) # Y.shape[1] = output char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "vEL3QGMch9N4",
    "outputId": "605ba06c-2a97-414a-cb6d-cd0c30c60593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 72, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 72, 256)           264192    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 72, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 796,700\n",
      "Trainable params: 796,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate1= 0.001 \n",
      "Epoch 1 to 50 \n",
      "\n",
      "Epoch 1/50\n",
      "129829/129829 [==============================] - 42s 320us/step - loss: 2.8241\n",
      "Epoch 2/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 2.6064\n",
      "Epoch 3/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 2.3865\n",
      "Epoch 4/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 2.2233\n",
      "Epoch 5/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 2.1014\n",
      "Epoch 6/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 2.0005\n",
      "Epoch 7/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.9208\n",
      "Epoch 8/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.8553\n",
      "Epoch 9/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.7954\n",
      "Epoch 10/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.7454\n",
      "Epoch 11/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.6981\n",
      "Epoch 12/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.6709\n",
      "Epoch 13/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.6339\n",
      "Epoch 14/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.5930\n",
      "Epoch 15/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.5564\n",
      "Epoch 16/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.5306\n",
      "Epoch 17/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.5001\n",
      "Epoch 18/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.4769\n",
      "Epoch 19/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.4529\n",
      "Epoch 20/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.4237\n",
      "Epoch 21/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.3996\n",
      "Epoch 22/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.3777\n",
      "Epoch 23/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.3560\n",
      "Epoch 24/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.3378\n",
      "Epoch 25/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.3122\n",
      "\n",
      "Epoch 00025: loss improved from inf to 1.31220, saving model to weights-25-1.3122.hdf5\n",
      "Epoch 26/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.2973\n",
      "Epoch 27/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.2795\n",
      "Epoch 28/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.2597\n",
      "Epoch 29/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.2399\n",
      "Epoch 30/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.2198\n",
      "Epoch 31/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.2037\n",
      "Epoch 32/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.1865\n",
      "Epoch 33/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.1710\n",
      "Epoch 34/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.1567\n",
      "Epoch 35/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.1380\n",
      "Epoch 36/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.1219\n",
      "Epoch 37/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.1084\n",
      "Epoch 38/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.0963\n",
      "Epoch 39/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.0785\n",
      "Epoch 40/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.0649\n",
      "Epoch 41/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.0497\n",
      "Epoch 42/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.0373\n",
      "Epoch 43/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 1.0218\n",
      "Epoch 44/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.0104\n",
      "Epoch 45/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 1.0004\n",
      "Epoch 46/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 0.9858\n",
      "Epoch 47/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 0.9726\n",
      "Epoch 48/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 0.9649\n",
      "Epoch 49/50\n",
      "129829/129829 [==============================] - 40s 309us/step - loss: 0.9520\n",
      "Epoch 50/50\n",
      "129829/129829 [==============================] - 40s 308us/step - loss: 0.9411\n",
      "\n",
      "Epoch 00050: loss improved from 1.31220 to 0.94106, saving model to weights-50-0.9411.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a11d52b38>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001))\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min', period=25)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(\"Learning Rate1= 0.001 \")\n",
    "print (\"Epoch 1 to 50 \\n\")\n",
    "# fit the model : \n",
    "model.fit(X, Y, epochs=50, batch_size=384, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate2= 0.0001 \n",
      "Epoch 50 to 100 \n",
      "\n",
      "Epoch 51/100\n",
      "129829/129829 [==============================] - 42s 321us/step - loss: 0.8512\n",
      "Epoch 52/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8330\n",
      "Epoch 53/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8244\n",
      "Epoch 54/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8196\n",
      "Epoch 55/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8144\n",
      "Epoch 56/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8129\n",
      "Epoch 57/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8087\n",
      "Epoch 58/100\n",
      "129829/129829 [==============================] - 40s 306us/step - loss: 0.8049\n",
      "Epoch 59/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8031\n",
      "Epoch 60/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.8004\n",
      "Epoch 61/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7975\n",
      "Epoch 62/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7941\n",
      "Epoch 63/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7916\n",
      "Epoch 64/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7910\n",
      "Epoch 65/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7870\n",
      "Epoch 66/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7884\n",
      "Epoch 67/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7839\n",
      "Epoch 68/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7836\n",
      "Epoch 69/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7788\n",
      "Epoch 70/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7777\n",
      "Epoch 71/100\n",
      "129829/129829 [==============================] - 40s 306us/step - loss: 0.7759\n",
      "Epoch 72/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7736\n",
      "Epoch 73/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7719\n",
      "Epoch 74/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7704\n",
      "Epoch 75/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7689\n",
      "\n",
      "Epoch 00075: loss improved from 0.94106 to 0.76894, saving model to weights-75-0.7689.hdf5\n",
      "Epoch 76/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7675\n",
      "Epoch 77/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7658\n",
      "Epoch 78/100\n",
      "129829/129829 [==============================] - 40s 306us/step - loss: 0.7633\n",
      "Epoch 79/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7604\n",
      "Epoch 80/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7578\n",
      "Epoch 81/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7578\n",
      "Epoch 82/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7551\n",
      "Epoch 83/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7535\n",
      "Epoch 84/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7519\n",
      "Epoch 85/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7494\n",
      "Epoch 86/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7493\n",
      "Epoch 87/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7467\n",
      "Epoch 88/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7426\n",
      "Epoch 89/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7436\n",
      "Epoch 90/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7403\n",
      "Epoch 91/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7400\n",
      "Epoch 92/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7370\n",
      "Epoch 93/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7364\n",
      "Epoch 94/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7366\n",
      "Epoch 95/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7323\n",
      "Epoch 96/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7310\n",
      "Epoch 97/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7313\n",
      "Epoch 98/100\n",
      "129829/129829 [==============================] - 40s 306us/step - loss: 0.7281\n",
      "Epoch 99/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7275\n",
      "Epoch 100/100\n",
      "129829/129829 [==============================] - 40s 307us/step - loss: 0.7253\n",
      "\n",
      "Epoch 00100: loss improved from 0.76894 to 0.72526, saving model to weights-100-0.7253.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6751e64f28>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_weights('weights-50-0.9411.hdf5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001))\n",
    "print(\"Learning Rate2= 0.0001 \")\n",
    "print (\"Epoch 50 to 100 \\n\")\n",
    "\n",
    "model.fit(X, Y, epochs=100, batch_size=384, initial_epoch=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "Generating Text with an LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Wkhykz2Ri5lY",
    "outputId": "7dc412c9-9c8e-44b3-c881-c00f10aa3f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the pattern to start with: 4928\n",
      "Seed:\n",
      "\" was just in time to hear it s########################################### \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1) #92908\n",
    "print(\"Index of the pattern to start with:\",start)\n",
    "pattern = dataX_padded[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\") \n",
    "\n",
    "pattern = list(dataX_padded[start]) #Numpy array to list\n",
    "\n",
    "# generate characters\n",
    "import sys\n",
    "output = ''\n",
    "for i in range(500):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    output = output+result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "BoVM5spiII9h",
    "outputId": "99c4e701-7674-444a-c5aa-bf0e9154f3eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Text: \n",
      " \n",
      " olethmy and bs iave aspu wale tuch lnlely and see as oncered werpenceradle of lt a vhry clarfe of toame of the werling but the waid to the wenl of the senembobtooo as homd the afded a said on her fach on wher stpp anice as speshngs the moew the waid to alice said bester whe hrownan and oore tatsed by tuatted poly as umeer the said tomeiers rres tuleking to the tueenened of toeased herser tenarked out repembir ins tie finis int ttill ie sayher when tuch a pear hirself anice as snee to deer or sle\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating Text: \\n \\n\", output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation_assignment_trail3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
